import streamlit as st
from openai import OpenAI
import cv2  # (V2) ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
import base64 # (V2) ì´ë¯¸ì§€ë¥¼ APIë¡œ ë³´ë‚´ê¸° ìœ„í•´
import tempfile # (V2) ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ ì €ì¥
import os       # (V2) ì„ì‹œ íŒŒì¼ ê´€ë¦¬

# -----------------------
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# -----------------------
st.set_page_config(page_title="ğŸ¬ AI ë¹„ë””ì˜¤ ê°ë… ì–´ì‹œìŠ¤í„´ìŠ¤", layout="wide")
st.title("ğŸ¬ AI ë¹„ë””ì˜¤ ê°ë…")
st.write("ì›í•˜ëŠ” ì‘ì—…ì„ íƒ­ì—ì„œ ì„ íƒí•˜ì„¸ìš”")

# -----------------------
# (ê³µí†µ) ì‚¬ì´ë“œë°”: API í‚¤ (Secretsì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
# -----------------------
st.sidebar.header("ğŸ”‘ (ê³µí†µ) API ì„¤ì •")

# Streamlit Cloudì— ë°°í¬ëœ ë²„ì „ì¸ì§€ í™•ì¸
if 'OPENAI_API_KEY' in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
    st.sidebar.success("API Keyê°€ ì•ˆì „í•˜ê²Œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© (ì„ íƒ ì‚¬í•­)
    st.sidebar.warning("Streamlit Cloud Secretsì— 'OPENAI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    # ë¡œì»¬ì—ì„œë§Œ ì„ì‹œë¡œ í‚¤ë¥¼ ì…ë ¥ë°›ê³  ì‹¶ë‹¤ë©´, ì´ì „ ì½”ë“œë¥¼ ì—¬ê¸°ì— ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    api_key = st.sidebar.text_input(
        "(ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©) OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        type="password",
        placeholder="sk-xxxxxxxxxxxxxxxx",
    )

# -----------------------
# (ê³µí†µ) V1, V2ì—ì„œ ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ì™€ í—¬í¼ í•¨ìˆ˜ ì •ì˜
# -----------------------

# (V1) ë²„ì „ 1ì—ì„œ ì‚¬ìš©í•  ì—­í•  ì •ì˜
V1_ROLES = {
    "ğŸ¥ Video Director": 
    "You are a professional film director. Always analyze ideas in terms of visual storytelling â€” use camera movement, lighting, framing, and emotional tone to explain your thoughts. Describe concepts as if you are planning a film scene.",
    
}

# (V2) ë²„ì „ 2ì—ì„œ ì‚¬ìš©í•  ê³ ì • ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
V2_SYSTEM_PROMPT = """
You are a professional film director and shot analyzer.
Your task is to analyze a series of video frames provided by the user.
Based on these frames, generate a detailed "prompt" that could be used by an AI video generator to create this exact scene.
Your analysis must include: Subject, Action, Scene Description, Cinematography (angle, movement, lighting), and Style.
Combine all of this into a concise, powerful prompt for an AI video generator.
"""

# (V2) ë²„ì „ 2ì—ì„œ ì‚¬ìš©í•  í—¬í¼ í•¨ìˆ˜
def process_video(video_path, seconds_per_frame, max_frames_to_send):
    """ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê³  Base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    base64_frames = []
    vid_cap = cv2.VideoCapture(video_path)
    
    fps = vid_cap.get(cv2.CAP_PROP_FPS)
    if fps == 0: fps = 30
    
    frame_interval = int(fps * seconds_per_frame)
    if frame_interval == 0: frame_interval = 1
            
    frame_count = 0
    
    while vid_cap.isOpened():
        ret, frame = vid_cap.read()
        if not ret:
            break
        
        if frame_count % frame_interval == 0:
            _, buffer = cv2.imencode(".jpg", frame)
            base64_frames.append(base64.b64encode(buffer).decode("utf-8"))
        
        frame_count += 1
        
        if len(base64_frames) >= max_frames_to_send:
            break
            
    vid_cap.release()
    return base64_frames

# -----------------------
# (ê³µí†µ) ë©”ì¸ í˜ì´ì§€ - íƒ­ ìƒì„±
# -----------------------
tab1, tab2 = st.tabs(["ğŸ¬ ë²„ì „ 1: í”„ë¡¬í”„íŠ¸ ë””ë²¨ë¡œí¼", "ğŸï¸ ë²„ì „ 2: ì˜ìƒ í”„ë¡¬í”„íŠ¸ ë¶„ì„ê¸°"])

# [ íƒ­ 1 ] ë²„ì „ 1: í”„ë¡¬í”„íŠ¸ ë””ë²¨ë¡œí¼ (ë¹„ë””ì˜¤ ê°ë… ì „ìš©)
# -----------------------
with tab1:
    st.header("ë²„ì „ 1: ì•„ì´ë””ì–´ë¥¼ ì˜ìƒìœ¼ë¡œ ë°œì „ì‹œí‚¤ê¸°")
    
    # --- (ìˆ˜ì •ë¨) V1 ì—­í• ì„ 'ë¹„ë””ì˜¤ ê°ë…'ìœ¼ë¡œ ê³ ì • ---
    # V1_ROLES ë”•ì…”ë„ˆë¦¬ ëŒ€ì‹ , ë¹„ë””ì˜¤ ê°ë… í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì •ì˜í•©ë‹ˆë‹¤.
    V1_SYSTEM_PROMPT = """
    You are a professional film director. Always analyze ideas in terms of visual storytelling â€” use camera movement, lighting, framing, and emotional tone to explain your thoughts. Describe concepts as if you are planning a film scene.
    """
    st.info(f"í˜„ì¬ ì—­í• : ğŸ¥ Video Director\n\n{V1_SYSTEM_PROMPT}")

    # V1 í…ìŠ¤íŠ¸ ì…ë ¥
    user_input_v1 = st.text_area(
        "ğŸ’¬ ë°œì „ì‹œí‚¤ê³  ì‹¶ì€ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        height=100,
        placeholder="ì˜ˆ: ë¹„ ì˜¤ëŠ” ë‚  ì°½ë°–ì„ ë³´ëŠ” ìŠ¬í”ˆ ë‚¨ì",
        key="v1_text_area"
    )
    
    # V1 ì‘ë‹µ ìƒì„± ë²„íŠ¼
    if st.button("í”„ë¡¬í”„íŠ¸ ë””ë²¨ë¡­í•˜ê¸°", key="v1_button"):
        if not api_key:
            st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not user_input_v1:
            st.warning("âš ï¸ ë°œì „ì‹œí‚¬ ì•„ì´ë””ì–´ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            try:
                client = OpenAI(api_key=api_key)
                with st.spinner("AI ê°ë…ì´ ì”¬ì„ êµ¬ìƒ ì¤‘ì…ë‹ˆë‹¤..."):
                    response = client.chat.completions.create(
                        model="gpt-4o-mini", # V1ì€ minië¡œë„ ì¶©ë¶„
                        messages=[
                            # (ìˆ˜ì •ë¨) 'role_description' ëŒ€ì‹  ì§ì ‘ ì •ì˜í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©
                            {"role": "system", "content": V1_SYSTEM_PROMPT},
                            {"role": "user", "content": user_input_v1}
                        ]
                    )
                    answer = response.choices[0].message.content
                    
                    # (ìˆ˜ì •ë¨) ì—­í•  ì´ë¦„ì„ "Video Director"ë¡œ ê³ ì •
                    st.success("ğŸ¬ Video Directorì˜ ì œì•ˆ:")
                    st.write(answer)
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# -----------------------
# [ íƒ­ 2 ] ë²„ì „ 2: ì˜ìƒ í”„ë¡¬í”„íŠ¸ ë¶„ì„ê¸°
# -----------------------
with tab2:
    st.header("ë²„ì „ 2: ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±í•˜ê¸°")
    st.info(f"AI ë¶„ì„ê°€ ì—­í• :\n{V2_SYSTEM_PROMPT}")

    # V2 íŒŒì¼ ì—…ë¡œë”
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (mp4, mov, avi):",
        type=["mp4", "mov", "avi"],
        key="v2_file_uploader"
    )

    # V2 ë¶„ì„ ì˜µì…˜
    st.subheader("ë¶„ì„ ì˜µì…˜")
    col1, col2 = st.columns(2)
    with col1:
        frame_sampling_rate = st.slider("í”„ë ˆì„ ìƒ˜í”Œë§ ê°„ê²© (ì´ˆ)", 0.5, 5.0, 1.0, 0.5,
                                        help="ëª‡ ì´ˆì— í•œ ë²ˆì”© ìŠ¤í¬ë¦°ìƒ·(í”„ë ˆì„)ì„ ì°ì–´ AIì—ê²Œ ë³´ë‚¼ì§€ ê²°ì •í•©ë‹ˆë‹¤.",
                                        key="v2_slider")
    with col2:
        max_frames = st.number_input("ì „ì†¡í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜", 5, 20, 10,
                                    help="AIì—ê²Œ í•œ ë²ˆì— ë³´ë‚¼ ìµœëŒ€ í”„ë ˆì„ ìˆ˜ì…ë‹ˆë‹¤.",
                                    key="v2_number_input")

    # V2 ì‘ë‹µ ìƒì„± ë²„íŠ¼
    if st.button("ë¹„ë””ì˜¤ ë¶„ì„ ë° í”„ë¡¬í”„íŠ¸ ìƒì„±", key="v2_button"):
        if not api_key:
            st.warning("âš ï¸ ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif uploaded_file is None:
            st.warning("âš ï¸ ë¹„ë””ì˜¤ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tfile:
                    tfile.write(uploaded_file.read())
                    video_path = tfile.name
                
                with st.spinner(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘... (ìµœëŒ€ {max_frames} í”„ë ˆì„ ìƒ˜í”Œë§)"):
                    base64_frames = process_video(video_path, frame_sampling_rate, max_frames)
                    
                if not base64_frames:
                    st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"{len(base64_frames)}ê°œì˜ í”„ë ˆì„ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤. AIì— ë¶„ì„ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
                    
                    # (ì„ íƒì‚¬í•­) í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°
                    # st.write("AIì— ì „ì†¡ëœ ìƒ˜í”Œ í”„ë ˆì„:")
                    # cols = st.columns(len(base64_frames))
                    # for i, frame_data in enumerate(base64_frames):
                    #     with cols[i]:
                    #         st.image(f"data:image/jpeg;base64,{frame_data}", use_column_width=True)

                    messages = [
                        {"role": "system", "content": V2_SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "ì´ ë¹„ë””ì˜¤ í”„ë ˆì„ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë¶„ì„í•˜ê³ , ì´ ì”¬ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                                *[
                                    {
                                        "type": "image_url",
                                        "image_url": {"url": f"data:image/jpeg;base64,{frame}"}
                                    } for frame in base64_frames
                                ]
                            ]
                        }
                    ]
                    
                    client = OpenAI(api_key=api_key)
                    with st.spinner("AI ê°ë…ì´ ì˜ìƒì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        response = client.chat.completions.create(
                            model="gpt-4o", # V2ëŠ” gpt-4o ê¶Œì¥
                            messages=messages,
                            max_tokens=1000 
                        )
                        answer = response.choices[0].message.content
                        st.subheader("ğŸ¬ AIê°€ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸")
                        st.write(answer)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            finally:
                if 'video_path' in locals() and os.path.exists(video_path):
                    os.remove(video_path)

# -----------------------
# (ê³µí†µ) í‘¸í„°
# -----------------------
st.markdown("---")
st.caption("Built for 'Art & Advanced Big Data' â€¢ Prof. Jahwan Koo (SKKU)")
